{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f583ba-24d4-483e-ad1a-fff77f8c7035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"figure.dpi\"] = 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb6493-3b2e-42f5-8525-b807eee4bf0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465b966-df59-4a23-b617-50dc884c2f40",
   "metadata": {},
   "source": [
    "## Mixture of Truncated Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81e8718-be77-4833-a2a0-2d0ca42dfb29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "\n",
    "def sample_mixture_truncnorm(n: int, random_state: RandomState = None) -> np.array:\n",
    "    if random_state is None:\n",
    "        random_state = RandomState()\n",
    "\n",
    "    scale = 0.1\n",
    "\n",
    "    loc = -0.6\n",
    "    a, b = (-1.0 - loc) / scale, (1.0 - loc) / scale\n",
    "    pos_samples = truncnorm.rvs(\n",
    "        a, b, loc=loc, scale=scale, size=2 * n, random_state=random_state\n",
    "    )\n",
    "\n",
    "    loc = 0.4\n",
    "    a, b = (-1.0 - loc) / scale, (1.0 - loc) / scale\n",
    "    neg_samples = truncnorm.rvs(\n",
    "        a, b, loc=loc, scale=scale, size=2 * n, random_state=random_state\n",
    "    )\n",
    "\n",
    "    all_samples = np.concatenate([pos_samples, neg_samples], axis=None)\n",
    "    random_state.shuffle(all_samples)\n",
    "\n",
    "    return all_samples.reshape((-1, 2))[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783f052-d85c-447b-a31b-675d981e8811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "truncnorm_data = sample_mixture_truncnorm(1000)\n",
    "plt.scatter(truncnorm_data[:, 0], truncnorm_data[:, 1])\n",
    "# plt.scatter([0.4, 0.4, -0.6, -0.6], [0.4, -0.6, 0.4, -0.6])\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9418781-8d44-4fcd-82e7-066629f674e2",
   "metadata": {},
   "source": [
    "## Two Moons Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84abce8c-c175-4667-b0d4-798aef98194e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "def sample_moons(size: int):\n",
    "    samples, _ = datasets.make_moons(n_samples=size, shuffle=True, noise=0.02)\n",
    "    samples[:, 0] -= 0.5\n",
    "    samples[:, 1] -= 0.2\n",
    "    samples[:, 0] /= 2.0\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342a462a-b4de-479d-805d-4ca02a21d53b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "moons_data = sample_moons(1000)\n",
    "plt.scatter(moons_data[:, 0], moons_data[:, 1])\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72c12aa-8cf5-4ce4-908a-4e91e79a7ee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-24T23:16:01.727050Z",
     "iopub.status.busy": "2023-04-24T23:16:01.726645Z",
     "iopub.status.idle": "2023-04-24T23:16:01.746378Z",
     "shell.execute_reply": "2023-04-24T23:16:01.744849Z",
     "shell.execute_reply.started": "2023-04-24T23:16:01.727023Z"
    },
    "tags": []
   },
   "source": [
    "# Naive K-Means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858ffe3-933f-4b51-b2e8-de831a01fb2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "truncnorm_data1 = sample_mixture_truncnorm(500_00)\n",
    "truncnorm_data2 = sample_mixture_truncnorm(500_00)\n",
    "truncnorm_kmeans1 = KMeans(n_clusters=3).fit(truncnorm_data1)\n",
    "truncnorm_kmeans2 = KMeans(n_clusters=3).fit(truncnorm_data2)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "truncnorm_data_indices1 = np.random.choice(\n",
    "    truncnorm_data1.shape[0], 10000, replace=False\n",
    ")\n",
    "\n",
    "ax[0].scatter(\n",
    "    truncnorm_data1[truncnorm_data_indices1, 0],\n",
    "    truncnorm_data1[truncnorm_data_indices1, 1],\n",
    "    label=\"Samples\",\n",
    ")\n",
    "# ax[0].scatter([0.4, 0.4, -0.6, -0.6], [0.4, -0.6, 0.4, -0.6])\n",
    "ax[0].scatter(\n",
    "    truncnorm_kmeans1.cluster_centers_[:, 0],\n",
    "    truncnorm_kmeans1.cluster_centers_[:, 1],\n",
    "    label=\"Computed Center\",\n",
    ")\n",
    "\n",
    "ax[0].set_xlim(-1, 1)\n",
    "ax[0].set_ylim(-1, 1)\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Execution 1\")\n",
    "\n",
    "truncnorm_data_indices2 = np.random.choice(\n",
    "    truncnorm_data2.shape[0], 10000, replace=False\n",
    ")\n",
    "\n",
    "ax[1].scatter(\n",
    "    truncnorm_data2[truncnorm_data_indices2, 0],\n",
    "    truncnorm_data2[truncnorm_data_indices2, 1],\n",
    "    label=\"Samples\",\n",
    ")\n",
    "# ax[1].scatter([0.4, 0.4, -0.6, -0.6], [0.4, -0.6, 0.4, -0.6])\n",
    "ax[1].scatter(\n",
    "    truncnorm_kmeans2.cluster_centers_[:, 0],\n",
    "    truncnorm_kmeans2.cluster_centers_[:, 1],\n",
    "    label=\"Computed Center\",\n",
    ")\n",
    "\n",
    "ax[1].set_xlim(-1, 1)\n",
    "ax[1].set_ylim(-1, 1)\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"Execution 2\")\n",
    "\n",
    "fig.suptitle(\"Non-Replicable K-Means++ on Truncated Gaussian Mixture\")\n",
    "\n",
    "plt.savefig(\"truncnorm.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b69e9-9154-4f16-a8ed-d3929abbde6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "moons_data1 = sample_moons(500_00)\n",
    "moons_data2 = sample_moons(500_00)\n",
    "moons_kmeans1 = KMeans(n_clusters=3).fit(moons_data1)\n",
    "moons_kmeans2 = KMeans(n_clusters=3).fit(moons_data2)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "moons_data_indices1 = np.random.choice(moons_data1.shape[0], 10000, replace=False)\n",
    "\n",
    "ax[0].scatter(\n",
    "    moons_data1[moons_data_indices1, 0],\n",
    "    moons_data1[moons_data_indices1, 1],\n",
    "    label=\"Samples\",\n",
    ")\n",
    "ax[0].scatter(\n",
    "    moons_kmeans1.cluster_centers_[:, 0],\n",
    "    moons_kmeans1.cluster_centers_[:, 1],\n",
    "    label=\"Computed Centers\",\n",
    ")\n",
    "\n",
    "ax[0].set_xlim(-1, 1)\n",
    "ax[0].set_ylim(-1, 1)\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Execution 1\")\n",
    "\n",
    "moons_data_indices2 = np.random.choice(moons_data2.shape[0], 10000, replace=False)\n",
    "\n",
    "ax[1].scatter(\n",
    "    moons_data2[moons_data_indices2, 0],\n",
    "    moons_data2[moons_data_indices2, 1],\n",
    "    label=\"Samples\",\n",
    ")\n",
    "ax[1].scatter(\n",
    "    moons_kmeans2.cluster_centers_[:, 0],\n",
    "    moons_kmeans2.cluster_centers_[:, 1],\n",
    "    label=\"Computed Centers\",\n",
    ")\n",
    "\n",
    "ax[1].set_xlim(-1, 1)\n",
    "ax[1].set_ylim(-1, 1)\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"Execution 2\")\n",
    "\n",
    "fig.suptitle(\"Non-Replicable K-Means++ on Two Moons Distribution\")\n",
    "\n",
    "plt.savefig(\"moons.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313ca2d-3dc2-42a8-b819-7bdd56554962",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Replicable K-Means++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02079a57-0700-4d72-b796-74c798ad582b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Replicable Heavy Hitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d08060a-6239-4854-93ae-a14c890025bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "\n",
    "def get_idx_intersect(A, B):\n",
    "    return (A[:, None] == B).all(-1).any(1)\n",
    "\n",
    "\n",
    "# 1-dimensional\n",
    "def r_heavy_hitters(\n",
    "    sampler, thres: float, eps: float, rho: float, delta: float, random_state: RandomState = None\n",
    "):\n",
    "    print(\"r_heavy_hitters...\")\n",
    "    assert 0 < thres < 1\n",
    "    assert 0 < eps < thres\n",
    "    assert 0 < rho < 1\n",
    "    assert 0 < delta <= rho/3\n",
    "\n",
    "    if random_state is None:\n",
    "        random_state = RandomState()\n",
    "\n",
    "    n1 = int(np.ceil(np.log(2 / (delta * (thres - eps))) / (thres - eps)))\n",
    "    print(n1)\n",
    "    candidates = sampler(size=n1)\n",
    "    candidates = np.unique(candidates, axis=0)\n",
    "\n",
    "    n2 = int(\n",
    "        np.ceil(\n",
    "            (np.log(2 / delta) + (np.sqrt(n1) + 1) * np.log(2))  # * 648\n",
    "            / (rho**2 * eps**2)\n",
    "        )\n",
    "    )\n",
    "    print(n2)\n",
    "    samples = sampler(size=n2)\n",
    "\n",
    "    unique_samples, count = np.unique(samples, axis=0, return_counts=True)\n",
    "    count = count.astype(float) / n2\n",
    "\n",
    "    rand_thres = random_state.uniform(thres - 2*eps/3, thres-eps/3)\n",
    "    print(count, rand_thres, n1 + n2)\n",
    "\n",
    "    # magic intersection https://stackoverflow.com/a/67113105\n",
    "    # get_idx_intersect(unique_samples, candidates)\n",
    "    _, idx_intersect, _ = np.intersect1d(\n",
    "        unique_samples, candidates, return_indices=True\n",
    "    )\n",
    "\n",
    "    unique_samples_intersect = unique_samples[idx_intersect]\n",
    "    count_intersect = count[idx_intersect]\n",
    "    return unique_samples_intersect[count_intersect >= rand_thres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973777f-81b7-4bbf-9073-ce2714b2425c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def toy_sampler(size: int, random_state: RandomState = None):\n",
    "    if random_state is None:\n",
    "        random_state = RandomState()\n",
    "\n",
    "    return np.random.choice([0, 1, 2], p=[0.3, 0.3, 0.4], size=size).reshape((-1, 1))\n",
    "\n",
    "\n",
    "print(\n",
    "    r_heavy_hitters(\n",
    "        toy_sampler, thres=0.4, eps=0.1, rho=0.4, delta=0.1, random_state=RandomState(2)\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    r_heavy_hitters(\n",
    "        toy_sampler, thres=0.4, eps=0.1, rho=0.4, delta=0.1, random_state=RandomState(2)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f395e-f8b6-49fc-98c0-7eb11202d791",
   "metadata": {},
   "source": [
    "## Replicable Quad Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd317b-d9ea-4d8e-b386-9f90205b306e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "\n",
    "class QuadTreeNode:\n",
    "    offsets = [np.array([dx, dy]) for dx, dy in product([-1.0, 1.0], repeat=2)]\n",
    "\n",
    "    def __init__(\n",
    "        self, point: np.array, radius: float, is_heavy: bool = False, parent=None\n",
    "    ):\n",
    "        self.point = point\n",
    "        self.radius = radius\n",
    "        self.is_heavy = is_heavy\n",
    "        self.children = [None] * 4\n",
    "        self.parent = parent\n",
    "\n",
    "    def get_heavy_nodes(self):\n",
    "        heavy_nodes = []\n",
    "\n",
    "        def _explore(node):\n",
    "            if not node.is_heavy:\n",
    "                return\n",
    "\n",
    "            heavy_nodes.append(node.point.reshape((1, -1)))\n",
    "            for child in node.children:\n",
    "                _explore(child)\n",
    "\n",
    "        _explore(self)\n",
    "        return np.concatenate(heavy_nodes, axis=0)\n",
    "\n",
    "    def get_leaves(self):\n",
    "        leaves = []\n",
    "\n",
    "        # return true if found node\n",
    "        def _explore(node) -> bool:\n",
    "            has_heavy_child = False\n",
    "            for child in node.children:\n",
    "                if child is not None and child.is_heavy:\n",
    "                    _explore(child)\n",
    "                    has_heavy_child = True\n",
    "\n",
    "            if not has_heavy_child:\n",
    "                leaves.append(node.point.reshape((1, -1)))\n",
    "\n",
    "            return has_heavy_child\n",
    "\n",
    "        _explore(self)\n",
    "        return np.concatenate(leaves, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c9a87e-6b58-4581-8ea1-878b73f6fd55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_children(nodes):\n",
    "    child_nodes = []\n",
    "    for node in nodes:\n",
    "        radius = node.radius\n",
    "        for idx, d in enumerate(QuadTreeNode.offsets):\n",
    "            next_point = node.point + d * radius / 2\n",
    "            child_node = QuadTreeNode(next_point, radius / 2, parent=node)\n",
    "\n",
    "            node.children[idx] = child_node\n",
    "            child_nodes.append(child_node)\n",
    "\n",
    "    return child_nodes\n",
    "\n",
    "\n",
    "def get_idx_sampler(sampler, nodes):\n",
    "    def _idx_sampler(size: int):\n",
    "        samples = sampler(size)\n",
    "        idx_samples = [len(nodes)] * size\n",
    "        for i in range(size):\n",
    "            for j in range(len(nodes)):\n",
    "                if (\n",
    "                    np.linalg.norm(samples[i] - nodes[j].point, ord=np.inf)\n",
    "                    <= nodes[j].radius\n",
    "                ):\n",
    "                    idx_samples[i] = j\n",
    "        return idx_samples\n",
    "\n",
    "    return _idx_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333cb716-d9ba-41c8-9897-09a4aac4bf6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "\n",
    "def r_quad_tree(\n",
    "    sampler,\n",
    "    k: int,\n",
    "    eps: float,\n",
    "    rho: float,\n",
    "    delta: float,\n",
    "    Gamma: float,\n",
    "    beta: float,\n",
    "    Delta: float = np.sqrt(2),\n",
    "    skip_layers: int = 1,\n",
    "    random_state: RandomState = None,\n",
    "):\n",
    "    assert 0 < eps < 1\n",
    "    assert 0 < rho < 1\n",
    "\n",
    "    t = 3  # int(np.ceil(1 / 2 * np.log(5 * Delta**2 / (eps * Gamma)) + 1))\n",
    "    M = (Delta / eps) ** 2  # * 2**10\n",
    "    gamma = eps / (t * k * M * Delta**2)  # / 20\n",
    "    print(t, M, gamma)\n",
    "\n",
    "    # build quad-tree\n",
    "    root = QuadTreeNode(point=np.array([0.0, 0.0]), radius=1.0, is_heavy=True)\n",
    "    H = [root]\n",
    "    i = 1\n",
    "    while H:\n",
    "        print(i)\n",
    "        if (2 ** (-i + 1) * Delta) ** 2 <= eps * Gamma / 5:\n",
    "            break\n",
    "\n",
    "        child_nodes = make_children(H)\n",
    "\n",
    "        if i <= skip_layers:  # skip first few layers\n",
    "            heavy_hitters = range(len(child_nodes))\n",
    "        else:\n",
    "            idx_sampler = get_idx_sampler(sampler, child_nodes)\n",
    "            thres = gamma * Gamma * 2 ** (2 * i)\n",
    "            heavy_hitters = r_heavy_hitters(\n",
    "                idx_sampler,\n",
    "                thres=thres,\n",
    "                eps=thres / 2,\n",
    "                rho=rho / t,\n",
    "                delta=delta / t,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "\n",
    "        H = []\n",
    "        for idx in heavy_hitters:\n",
    "            if idx < len(child_nodes):\n",
    "                child_nodes[idx].is_heavy = True\n",
    "                H.append(child_nodes[idx])\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14aa40e-0820-4342-b0d9-988a108dd57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root1 = r_quad_tree(\n",
    "    sample_mixture_truncnorm,\n",
    "    k=3,\n",
    "    eps=0.99,\n",
    "    rho=0.4,\n",
    "    delta=0.1,\n",
    "    Gamma=0.5,\n",
    "    beta=1.0,\n",
    "    Delta=np.sqrt(2),\n",
    "    random_state=RandomState(2),\n",
    ")\n",
    "\n",
    "root2 = r_quad_tree(\n",
    "    sample_mixture_truncnorm,\n",
    "    k=3,\n",
    "    eps=0.99,\n",
    "    rho=0.4,\n",
    "    delta=0.1,\n",
    "    Gamma=0.5,\n",
    "    beta=1.0,\n",
    "    Delta=np.sqrt(2),\n",
    "    random_state=RandomState(2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261d9b6-6c9d-4c6f-b61c-3f98c6c2ef39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "heavy_nodes1 = root1.get_leaves()\n",
    "heavy_nodes2 = root2.get_leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b4b3cf-3849-4bb9-a114-905c7cf14de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(truncnorm_data[:, 0], truncnorm_data[:, 1], label=\"Samples\")\n",
    "# plt.scatter([0.4, 0.4, -0.6, -0.6], [0.4, -0.6, 0.4, -0.6], label=\"Mixture Centers\")\n",
    "plt.scatter(\n",
    "    heavy_nodes1[:, 0],\n",
    "    heavy_nodes1[:, 1],\n",
    "    marker=\"1\",\n",
    "    linewidths=10,\n",
    "    label=\"Heavy Leaves Execution 1\",\n",
    ")\n",
    "plt.scatter(\n",
    "    heavy_nodes1[:, 0],\n",
    "    heavy_nodes1[:, 1],\n",
    "    marker=\"2\",\n",
    "    linewidths=10,\n",
    "    label=\"Heavy Leaves Execution 2\",\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e68578-3e02-4bce-a7d3-09b7b7d5a486",
   "metadata": {},
   "source": [
    "## Replicable Probability Mass Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677e3d6-7817-4088-83a8-0c5c639a4636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eps should be a power of 10 e.g. 1e-3\n",
    "def r_prob_mass(sampler, N: int, rho: float, eps: float, delta: float, random_state: RandomState):\n",
    "    assert 0 < rho < 1\n",
    "    assert 0 < eps < 1\n",
    "    assert 0 < delta < rho/3\n",
    "\n",
    "    alpha = 2 * eps / (rho - 2*delta + 1)\n",
    "    eps_prime = eps * (rho - 2*delta) / (rho + 1 - 2*delta)\n",
    "    n = int(np.ceil((np.log(1/delta) + N * np.log(2)) / (eps**2 * (rho - 2*delta)**2))) * 2\n",
    "    decimals = int(np.log10(1 / eps))\n",
    "    print(alpha, eps_prime, n, decimals)\n",
    "\n",
    "    samples = sampler(size=n)\n",
    "    unique_samples, count = np.unique(samples, axis=0, return_counts=True)\n",
    "    len(unique_samples) <= N\n",
    "    count = count.astype(float) / n\n",
    "\n",
    "    offset = random_state.uniform(low=0.0, high=alpha, size=len(unique_samples))\n",
    "    rounded_count = np.around(count - offset, decimals=decimals) + offset\n",
    "\n",
    "    # normalize estimates\n",
    "    return unique_samples, rounded_count - (rounded_count.sum() - 1.0) / len(\n",
    "        unique_samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92241358-ca59-4a9d-a9fe-6f0da6f095bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "samples1, mass1 = r_prob_mass(\n",
    "    toy_sampler, N=3, rho=0.4, eps=0.1, delta=0.1, random_state=RandomState(2)\n",
    ")\n",
    "samples2, mass2 = r_prob_mass(\n",
    "    toy_sampler, N=3, rho=0.4, eps=0.1, delta=0.1, random_state=RandomState(2)\n",
    ")\n",
    "\n",
    "assert np.isclose(mass1.sum(), 1.0)\n",
    "assert np.isclose(mass2.sum(), 1.0)\n",
    "\n",
    "print(samples1, mass1)\n",
    "print(samples2, mass2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8284df5-368e-4f4a-8dbe-1dfb9a0f1dc4",
   "metadata": {},
   "source": [
    "## Replicable Coreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977237c7-e7d4-4af8-83f5-f80dbebe75c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_child_idx(node, point):\n",
    "    if point[0] < node.point[0]:\n",
    "        if point[1] < node.point[1]:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if point[1] < node.point[1]:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "\n",
    "def quad_tree_round(point, root: QuadTreeNode):\n",
    "    output = np.array([0.0, 0.0])\n",
    "\n",
    "    node = root\n",
    "    while node is not None:\n",
    "        child_idx = get_child_idx(node, point)\n",
    "\n",
    "        if node.children[child_idx] is not None and node.children[child_idx].is_heavy:\n",
    "            node = node.children[child_idx]\n",
    "            output = node.point\n",
    "            continue\n",
    "\n",
    "        new_node = None\n",
    "        for idx in range(len(QuadTreeNode.offsets)):\n",
    "            if node.children[idx] is not None and node.children[idx].is_heavy:\n",
    "                new_node = node.children[idx]\n",
    "                output = new_node.point\n",
    "                break\n",
    "\n",
    "        node = new_node\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def make_quad_tree_sampler(sampler, root: QuadTreeNode):\n",
    "    def _quad_tree_sampler(size: int):\n",
    "        samples = sampler(size)\n",
    "        for i in range(len(samples)):\n",
    "            samples[i] = quad_tree_round(samples[i], root)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    return _quad_tree_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810cd0ed-8061-4286-95bb-21cd082b8e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quad_tree_sampler1 = make_quad_tree_sampler(sample_mixture_truncnorm, root1)\n",
    "quad_tree_sampler2 = make_quad_tree_sampler(sample_mixture_truncnorm, root2)\n",
    "\n",
    "samples1 = quad_tree_sampler1(1000)\n",
    "samples2 = quad_tree_sampler2(1000)\n",
    "\n",
    "plt.scatter(\n",
    "    samples1[:, 0],\n",
    "    samples1[:, 1],\n",
    "    marker=\"1\",\n",
    "    linewidths=10,\n",
    "    label=\"Coreset Execution 1\",\n",
    ")\n",
    "plt.scatter(\n",
    "    samples2[:, 0],\n",
    "    samples2[:, 1],\n",
    "    marker=\"2\",\n",
    "    linewidths=10,\n",
    "    label=\"Coreset Execution 1\",\n",
    ")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8633ece6-2490-4054-a9ad-a69292eaf2a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def r_coreset(\n",
    "    sampler,\n",
    "    k: int,\n",
    "    eps: float,\n",
    "    rho: float,\n",
    "    delta: float,\n",
    "    Gamma: float,\n",
    "    beta: float,\n",
    "    Delta: float = np.sqrt(2),\n",
    "    skip_layers: int = 1,\n",
    "    random_state: RandomState = None,\n",
    "):\n",
    "    assert 0 < eps < 1\n",
    "    assert 0 < rho < 1\n",
    "    assert 0 < delta < rho/3\n",
    "\n",
    "    if random_state is None:\n",
    "        random_state = RandomState()\n",
    "\n",
    "    root = r_quad_tree(\n",
    "        sampler,\n",
    "        k=k,\n",
    "        eps=eps,\n",
    "        rho=rho,\n",
    "        delta=delta,\n",
    "        Gamma=Gamma,\n",
    "        beta=beta,\n",
    "        Delta=Delta,\n",
    "        skip_layers=skip_layers,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    N = len(root.get_leaves())\n",
    "\n",
    "    quad_tree_sampler = make_quad_tree_sampler(sampler, root)\n",
    "    coreset, mass = r_prob_mass(\n",
    "        quad_tree_sampler, N=N, rho=0.1, eps=0.1, delta=0.01, random_state=random_state\n",
    "    )\n",
    "\n",
    "    return coreset, mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec3eb25-d247-4f67-813a-1080d280f73f",
   "metadata": {},
   "source": [
    "## Replicable K-Means++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc200b-5512-434a-8b6b-ee975580950a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MemorizedSampler:\n",
    "    def __init__(self, sampler):\n",
    "        self.sampler = sampler\n",
    "        self.samples = []\n",
    "\n",
    "    def __call__(self, size: int):\n",
    "        samples = self.sampler(size)\n",
    "        self.samples.append(samples.copy())\n",
    "        return samples\n",
    "\n",
    "    def get_samples(self):\n",
    "        return np.concatenate(self.samples, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52904b8-7426-4e77-81e4-82f509fc4758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memorized_truncnorm_sampler1 = MemorizedSampler(sample_mixture_truncnorm)\n",
    "truncnorm_coreset1, truncnorm_mass1 = r_coreset(\n",
    "    memorized_truncnorm_sampler1,\n",
    "    k=3,\n",
    "    eps=0.99,\n",
    "    rho=0.3,\n",
    "    delta=0.01,\n",
    "    Gamma=0.5,\n",
    "    beta=1.0,\n",
    "    Delta=np.sqrt(2),\n",
    "    random_state=RandomState(2),\n",
    ")\n",
    "\n",
    "memorized_truncnorm_sampler2 = MemorizedSampler(sample_mixture_truncnorm)\n",
    "truncnorm_coreset2, truncnorm_mass2 = r_coreset(\n",
    "    memorized_truncnorm_sampler2,\n",
    "    k=3,\n",
    "    eps=0.99,\n",
    "    rho=0.3,\n",
    "    delta=0.01,\n",
    "    Gamma=0.5,\n",
    "    beta=1.0,\n",
    "    Delta=np.sqrt(2),\n",
    "    random_state=RandomState(2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110e3483-26b2-452c-98e4-55d1b390ba74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "r_truncnorm_kmeans1 = KMeans(n_clusters=3).fit(\n",
    "    truncnorm_coreset1, sample_weight=truncnorm_mass1\n",
    ")\n",
    "r_truncnorm_kmeans2 = KMeans(n_clusters=3).fit(\n",
    "    truncnorm_coreset2, sample_weight=truncnorm_mass2\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "memorized_truncnorm_data1 = memorized_truncnorm_sampler1.get_samples()\n",
    "print(f\"used {len(memorized_truncnorm_data1)} samples\")\n",
    "memorized_truncnorm_data_indices1 = np.random.choice(\n",
    "    memorized_truncnorm_data1.shape[0], 10000, replace=False\n",
    ")\n",
    "\n",
    "ax[0].scatter(\n",
    "    memorized_truncnorm_data1[memorized_truncnorm_data_indices1, 0],\n",
    "    memorized_truncnorm_data1[memorized_truncnorm_data_indices1, 1],\n",
    "    label=\"Samples\",\n",
    ")\n",
    "# ax[0].scatter([0.4, 0.4, -0.6, -0.6], [0.4, -0.6, 0.4, -0.6])\n",
    "ax[0].scatter(\n",
    "    r_truncnorm_kmeans1.cluster_centers_[:, 0],\n",
    "    r_truncnorm_kmeans1.cluster_centers_[:, 1],\n",
    "    label=\"Computed Centers\",\n",
    ")\n",
    "\n",
    "ax[0].scatter(\n",
    "    truncnorm_coreset1[:, 0],\n",
    "    truncnorm_coreset1[:, 1],\n",
    "    marker=\"1\",\n",
    "    # linewidths=10,\n",
    "    label=\"Coreset\",\n",
    ")\n",
    "\n",
    "ax[0].set_xlim(-1, 1)\n",
    "ax[0].set_ylim(-1, 1)\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Execution 1\")\n",
    "\n",
    "memorized_truncnorm_data2 = memorized_truncnorm_sampler2.get_samples()\n",
    "print(f\"used {len(memorized_truncnorm_data2)} samples\")\n",
    "memorized_truncnorm_data_indices2 = np.random.choice(\n",
    "    memorized_truncnorm_data2.shape[0], 10000, replace=False\n",
    ")\n",
    "\n",
    "ax[1].scatter(\n",
    "    memorized_truncnorm_data2[memorized_truncnorm_data_indices2, 0],\n",
    "    memorized_truncnorm_data2[memorized_truncnorm_data_indices2, 1],\n",
    "    label=\"Samples\",\n",
    ")\n",
    "# ax[1].scatter([0.4, 0.4, -0.6, -0.6], [0.4, -0.6, 0.4, -0.6])\n",
    "ax[1].scatter(\n",
    "    r_truncnorm_kmeans2.cluster_centers_[:, 0],\n",
    "    r_truncnorm_kmeans2.cluster_centers_[:, 1],\n",
    "    label=\"Computed Centers\",\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    truncnorm_coreset2[:, 0],\n",
    "    truncnorm_coreset2[:, 1],\n",
    "    marker=\"1\",\n",
    "    # linewidths=10,\n",
    "    label=\"Coreset\",\n",
    ")\n",
    "\n",
    "ax[1].set_xlim(-1, 1)\n",
    "ax[1].set_ylim(-1, 1)\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"Execution 2\")\n",
    "\n",
    "fig.suptitle(\"Replicable K-Means++ on Truncated Gaussian Mixture\")\n",
    "\n",
    "plt.savefig(\"r_truncnorm.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ccc436-70eb-49fa-a09f-bbcf84e48fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memorized_moons_sampler1 = MemorizedSampler(sample_moons)\n",
    "moons_coreset1, moons_mass1 = r_coreset(\n",
    "    memorized_moons_sampler1,\n",
    "    k=3,\n",
    "    eps=0.99,\n",
    "    rho=0.4,\n",
    "    delta=0.1,\n",
    "    Gamma=0.5,\n",
    "    beta=1.0,\n",
    "    Delta=np.sqrt(2),\n",
    "    random_state=RandomState(2),\n",
    ")\n",
    "\n",
    "memorized_moons_sampler2 = MemorizedSampler(sample_moons)\n",
    "moons_coreset2, moons_mass2 = r_coreset(\n",
    "    memorized_moons_sampler2,\n",
    "    k=3,\n",
    "    eps=0.99,\n",
    "    rho=0.4,\n",
    "    delta=0.1,\n",
    "    Gamma=0.5,\n",
    "    beta=1.0,\n",
    "    Delta=np.sqrt(2),\n",
    "    random_state=RandomState(2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a338994-8fd8-43a8-9edb-1d1b0a8b188a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r_moons_kmeans1 = KMeans(n_clusters=3).fit(moons_coreset1, sample_weight=moons_mass1)\n",
    "r_moons_kmeans2 = KMeans(n_clusters=3).fit(moons_coreset2, sample_weight=moons_mass2)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "memorized_moons_data1 = memorized_moons_sampler1.get_samples()\n",
    "print(f\"used {len(memorized_moons_data1)} samples\")\n",
    "memorized_moons_data_indices1 = np.random.choice(\n",
    "    memorized_moons_data1.shape[0], 10000, replace=False\n",
    ")\n",
    "\n",
    "ax[0].scatter(\n",
    "    memorized_moons_data1[memorized_moons_data_indices1, 0],\n",
    "    memorized_moons_data1[memorized_moons_data_indices1, 1],\n",
    "    label=\"Samples\",\n",
    ")\n",
    "ax[0].scatter(\n",
    "    r_moons_kmeans1.cluster_centers_[:, 0],\n",
    "    r_moons_kmeans1.cluster_centers_[:, 1],\n",
    "    label=\"Computed Centers\",\n",
    ")\n",
    "\n",
    "ax[0].scatter(\n",
    "    moons_coreset1[:, 0],\n",
    "    moons_coreset1[:, 1],\n",
    "    marker=\"1\",\n",
    "    # linewidths=10,\n",
    "    label=\"Coreset\",\n",
    ")\n",
    "\n",
    "ax[0].set_xlim(-1, 1)\n",
    "ax[0].set_ylim(-1, 1)\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Execution 1\")\n",
    "\n",
    "memorized_moons_data2 = memorized_moons_sampler2.get_samples()\n",
    "print(f\"used {len(memorized_moons_data2)} samples\")\n",
    "memorized_moons_data_indices2 = np.random.choice(\n",
    "    memorized_moons_data2.shape[0], 10000, replace=False\n",
    ")\n",
    "\n",
    "ax[1].scatter(\n",
    "    memorized_moons_data2[memorized_moons_data_indices2, 0],\n",
    "    memorized_moons_data2[memorized_moons_data_indices2, 1],\n",
    "    label=\"Samples\",\n",
    ")\n",
    "ax[1].scatter(\n",
    "    r_moons_kmeans2.cluster_centers_[:, 0],\n",
    "    r_moons_kmeans2.cluster_centers_[:, 1],\n",
    "    label=\"Computed Centers\",\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    moons_coreset2[:, 0],\n",
    "    moons_coreset2[:, 1],\n",
    "    marker=\"1\",\n",
    "    # linewidths=10,\n",
    "    label=\"Coreset\",\n",
    ")\n",
    "\n",
    "ax[1].set_xlim(-1, 1)\n",
    "ax[1].set_ylim(-1, 1)\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"Execution 2\")\n",
    "\n",
    "fig.suptitle(\"Replicable K-Means++ on Two Moons Distribution\")\n",
    "\n",
    "plt.savefig(\"r_moons.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22b876-fefa-4802-b7b6-1022a4088e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
